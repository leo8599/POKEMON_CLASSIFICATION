{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "179706c3-72d5-45fd-996f-73c68cb530ba",
   "metadata": {},
   "source": [
    "## Pokemon classification (with transfer learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3b8c56b-ed7e-4c04-9bb6-1badb077f4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] torch/torchvision versions not as required, installing nightly versions.\n",
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
      "Requirement already satisfied: torch in /opt/homebrew/Caskroom/miniconda/base/envs/ds_env/lib/python3.10/site-packages (2.9.1)\n",
      "Requirement already satisfied: torchvision in /opt/homebrew/Caskroom/miniconda/base/envs/ds_env/lib/python3.10/site-packages (0.24.1)\n",
      "Requirement already satisfied: torchaudio in /opt/homebrew/Caskroom/miniconda/base/envs/ds_env/lib/python3.10/site-packages (2.9.1)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/Caskroom/miniconda/base/envs/ds_env/lib/python3.10/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/homebrew/Caskroom/miniconda/base/envs/ds_env/lib/python3.10/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/homebrew/Caskroom/miniconda/base/envs/ds_env/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/homebrew/Caskroom/miniconda/base/envs/ds_env/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/Caskroom/miniconda/base/envs/ds_env/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /opt/homebrew/Caskroom/miniconda/base/envs/ds_env/lib/python3.10/site-packages (from torch) (2025.7.0)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/Caskroom/miniconda/base/envs/ds_env/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/homebrew/Caskroom/miniconda/base/envs/ds_env/lib/python3.10/site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/ds_env/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/ds_env/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "torch version: 2.5.1\n",
      "torchvision version: 0.20.1\n"
     ]
    }
   ],
   "source": [
    "# For this notebook to run with updated APIs, we need torch 1.12+ and torchvision 0.13+\n",
    "try:\n",
    "    import torch\n",
    "    import torchvision\n",
    "    assert int(torch.__version__.split(\".\")[1]) >= 12, \"torch version should be 1.12+\"\n",
    "    assert int(torchvision.__version__.split(\".\")[1]) >= 13, \"torchvision version should be 0.13+\"\n",
    "    print(f\"torch version: {torch.__version__}\")\n",
    "    print(f\"torchvision version: {torchvision.__version__}\")\n",
    "except:\n",
    "    print(f\"[INFO] torch/torchvision versions not as required, installing nightly versions.\")\n",
    "    !pip3 install -U torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "    import torch\n",
    "    import torchvision\n",
    "    print(f\"torch version: {torch.__version__}\")\n",
    "    print(f\"torchvision version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "192ebbb4-55e6-4687-ba3e-82f88a888469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue with regular imports\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "\n",
    "# Try to get torchinfo, install it if it doesn't work\n",
    "try:\n",
    "    from torchinfo import summary\n",
    "except:\n",
    "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
    "    !pip install -q torchinfo\n",
    "    from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f7e5824-b73a-4e40-98ec-ecddc145c913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b54dbfb-daa5-4652-9030-d29be309988a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Dirs\n",
    "train_dir = \"../data/train/\"\n",
    "test_dir = \"../data/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31775b3f-e2e2-456e-a148-cbb2cb147649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transforms pipeline manually (required for torchvision < 0.13)\n",
    "manual_transforms = transforms.Compose([\n",
    "    transforms.Resize((64, 64)), # 1. Reshape all images to 64x64 (though some models may require different sizes)\n",
    "    transforms.ToTensor(), # 2. Turn image values to between 0 & 1 \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], # 3. A mean of [0.485, 0.456, 0.406] (across each colour channel)\n",
    "                         std=[0.229, 0.224, 0.225]) # 4. A standard deviation of [0.229, 0.224, 0.225] (across each colour channel),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04cb2eca-55f5-4d98-b8a5-6006f9ecdb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "def create_dataloaders(\n",
    "    train_dir: str, \n",
    "    test_dir: str, \n",
    "    transform: transforms.Compose, \n",
    "    batch_size: int, \n",
    "    num_workers: int=NUM_WORKERS\n",
    "):\n",
    "  \"\"\"Creates training and testing DataLoaders.\n",
    "\n",
    "  Takes in a training directory and testing directory path and turns\n",
    "  them into PyTorch Datasets and then into PyTorch DataLoaders.\n",
    "\n",
    "  Args:\n",
    "    train_dir: Path to training directory.\n",
    "    test_dir: Path to testing directory.\n",
    "    transform: torchvision transforms to perform on training and testing data.\n",
    "    batch_size: Number of samples per batch in each of the DataLoaders.\n",
    "    num_workers: An integer for number of workers per DataLoader.\n",
    "\n",
    "  Returns:\n",
    "    A tuple of (train_dataloader, test_dataloader, class_names).\n",
    "    Where class_names is a list of the target classes.\n",
    "    Example usage:\n",
    "      train_dataloader, test_dataloader, class_names = \\\n",
    "        = create_dataloaders(train_dir=path/to/train_dir,\n",
    "                             test_dir=path/to/test_dir,\n",
    "                             transform=some_transform,\n",
    "                             batch_size=32,\n",
    "                             num_workers=4)\n",
    "  \"\"\"\n",
    "  # Use ImageFolder to create dataset(s)\n",
    "  train_data = datasets.ImageFolder(train_dir, transform=transform)\n",
    "  test_data = datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "  # Get class names\n",
    "  class_names = train_data.classes\n",
    "\n",
    "  # Turn images into data loaders\n",
    "  train_dataloader = DataLoader(\n",
    "      train_data,\n",
    "      batch_size=batch_size,\n",
    "      shuffle=True,\n",
    "      num_workers=num_workers,\n",
    "      pin_memory=True,\n",
    "  )\n",
    "  test_dataloader = DataLoader(\n",
    "      test_data,\n",
    "      batch_size=batch_size,\n",
    "      shuffle=False, # don't need to shuffle test data\n",
    "      num_workers=num_workers,\n",
    "      pin_memory=True,\n",
    "  )\n",
    "\n",
    "  return train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d946a284-276b-4ff7-8bce-64ffcf140cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x14db47eb0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x176744af0>,\n",
       " ['Abra',\n",
       "  'Aerodactyl',\n",
       "  'Alakazam',\n",
       "  'Alolan Sandslash',\n",
       "  'Arbok',\n",
       "  'Arcanine',\n",
       "  'Articuno',\n",
       "  'Beedrill',\n",
       "  'Bellsprout',\n",
       "  'Blastoise',\n",
       "  'Bulbasaur',\n",
       "  'Butterfree',\n",
       "  'Caterpie',\n",
       "  'Chansey',\n",
       "  'Charizard',\n",
       "  'Charmander',\n",
       "  'Charmeleon',\n",
       "  'Clefable',\n",
       "  'Clefairy',\n",
       "  'Cloyster',\n",
       "  'Cubone',\n",
       "  'Dewgong',\n",
       "  'Diglett',\n",
       "  'Ditto',\n",
       "  'Dodrio',\n",
       "  'Doduo',\n",
       "  'Dragonair',\n",
       "  'Dragonite',\n",
       "  'Dratini',\n",
       "  'Drowzee',\n",
       "  'Dugtrio',\n",
       "  'Eevee',\n",
       "  'Ekans',\n",
       "  'Electabuzz',\n",
       "  'Electrode',\n",
       "  'Exeggcute',\n",
       "  'Exeggutor',\n",
       "  'Farfetchd',\n",
       "  'Fearow',\n",
       "  'Flareon',\n",
       "  'Gastly',\n",
       "  'Gengar',\n",
       "  'Geodude',\n",
       "  'Gloom',\n",
       "  'Golbat',\n",
       "  'Goldeen',\n",
       "  'Golduck',\n",
       "  'Golem',\n",
       "  'Graveler',\n",
       "  'Grimer',\n",
       "  'Growlithe',\n",
       "  'Gyarados',\n",
       "  'Haunter',\n",
       "  'Hitmonchan',\n",
       "  'Hitmonlee',\n",
       "  'Horsea',\n",
       "  'Hypno',\n",
       "  'Ivysaur',\n",
       "  'Jigglypuff',\n",
       "  'Jolteon',\n",
       "  'Jynx',\n",
       "  'Kabuto',\n",
       "  'Kabutops',\n",
       "  'Kadabra',\n",
       "  'Kakuna',\n",
       "  'Kangaskhan',\n",
       "  'Kingler',\n",
       "  'Koffing',\n",
       "  'Krabby',\n",
       "  'Lapras',\n",
       "  'Lickitung',\n",
       "  'Machamp',\n",
       "  'Machoke',\n",
       "  'Machop',\n",
       "  'Magikarp',\n",
       "  'Magmar',\n",
       "  'Magnemite',\n",
       "  'Magneton',\n",
       "  'Mankey',\n",
       "  'Marowak',\n",
       "  'Meowth',\n",
       "  'Metapod',\n",
       "  'Mew',\n",
       "  'Mewtwo',\n",
       "  'Moltres',\n",
       "  'MrMime',\n",
       "  'Muk',\n",
       "  'Nidoking',\n",
       "  'Nidoqueen',\n",
       "  'Nidorina',\n",
       "  'Nidorino',\n",
       "  'Ninetales',\n",
       "  'Oddish',\n",
       "  'Omanyte',\n",
       "  'Omastar',\n",
       "  'Onix',\n",
       "  'Paras',\n",
       "  'Parasect',\n",
       "  'Persian',\n",
       "  'Pidgeot',\n",
       "  'Pidgeotto',\n",
       "  'Pidgey',\n",
       "  'Pikachu',\n",
       "  'Pinsir',\n",
       "  'Poliwag',\n",
       "  'Poliwhirl',\n",
       "  'Poliwrath',\n",
       "  'Ponyta',\n",
       "  'Porygon',\n",
       "  'Primeape',\n",
       "  'Psyduck',\n",
       "  'Raichu',\n",
       "  'Rapidash',\n",
       "  'Raticate',\n",
       "  'Rattata',\n",
       "  'Rhydon',\n",
       "  'Rhyhorn',\n",
       "  'Sandshrew',\n",
       "  'Sandslash',\n",
       "  'Scyther',\n",
       "  'Seadra',\n",
       "  'Seaking',\n",
       "  'Seel',\n",
       "  'Shellder',\n",
       "  'Slowbro',\n",
       "  'Slowpoke',\n",
       "  'Snorlax',\n",
       "  'Spearow',\n",
       "  'Squirtle',\n",
       "  'Starmie',\n",
       "  'Staryu',\n",
       "  'Tangela',\n",
       "  'Tauros',\n",
       "  'Tentacool',\n",
       "  'Tentacruel',\n",
       "  'Vaporeon',\n",
       "  'Venomoth',\n",
       "  'Venonat',\n",
       "  'Venusaur',\n",
       "  'Victreebel',\n",
       "  'Vileplume',\n",
       "  'Voltorb',\n",
       "  'Vulpix',\n",
       "  'Wartortle',\n",
       "  'Weedle',\n",
       "  'Weepinbell',\n",
       "  'Weezing',\n",
       "  'Wigglytuff',\n",
       "  'Zapdos',\n",
       "  'Zubat'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataLoaders with help from data_setup.py\n",
    "train_dataloader, test_dataloader, class_names = create_dataloaders(\n",
    "    train_dir=train_dir,\n",
    "    test_dir=test_dir,\n",
    "    transform=manual_transforms,\n",
    "    batch_size=32\n",
    "    )\n",
    "train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c0d68b4-0537-4f93-af69-177b0261b3b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet_B0_Weights.IMAGENET1K_V1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a set of pretrained model weights\n",
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT # .DEFAULT = best available weights from pretraining on ImageNet\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cdc57913-1fd1-4ae1-8249-7a39ac5e37ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassification(\n",
       "    crop_size=[224]\n",
       "    resize_size=[256]\n",
       "    mean=[0.485, 0.456, 0.406]\n",
       "    std=[0.229, 0.224, 0.225]\n",
       "    interpolation=InterpolationMode.BICUBIC\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the transforms used to create our pretrained weights\n",
    "auto_transforms = weights.transforms()\n",
    "auto_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "adef6ac0-09e9-4886-9c54-cd3c7f72a313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x1766e8a00>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x1766e45e0>,\n",
       " ['Abra',\n",
       "  'Aerodactyl',\n",
       "  'Alakazam',\n",
       "  'Alolan Sandslash',\n",
       "  'Arbok',\n",
       "  'Arcanine',\n",
       "  'Articuno',\n",
       "  'Beedrill',\n",
       "  'Bellsprout',\n",
       "  'Blastoise',\n",
       "  'Bulbasaur',\n",
       "  'Butterfree',\n",
       "  'Caterpie',\n",
       "  'Chansey',\n",
       "  'Charizard',\n",
       "  'Charmander',\n",
       "  'Charmeleon',\n",
       "  'Clefable',\n",
       "  'Clefairy',\n",
       "  'Cloyster',\n",
       "  'Cubone',\n",
       "  'Dewgong',\n",
       "  'Diglett',\n",
       "  'Ditto',\n",
       "  'Dodrio',\n",
       "  'Doduo',\n",
       "  'Dragonair',\n",
       "  'Dragonite',\n",
       "  'Dratini',\n",
       "  'Drowzee',\n",
       "  'Dugtrio',\n",
       "  'Eevee',\n",
       "  'Ekans',\n",
       "  'Electabuzz',\n",
       "  'Electrode',\n",
       "  'Exeggcute',\n",
       "  'Exeggutor',\n",
       "  'Farfetchd',\n",
       "  'Fearow',\n",
       "  'Flareon',\n",
       "  'Gastly',\n",
       "  'Gengar',\n",
       "  'Geodude',\n",
       "  'Gloom',\n",
       "  'Golbat',\n",
       "  'Goldeen',\n",
       "  'Golduck',\n",
       "  'Golem',\n",
       "  'Graveler',\n",
       "  'Grimer',\n",
       "  'Growlithe',\n",
       "  'Gyarados',\n",
       "  'Haunter',\n",
       "  'Hitmonchan',\n",
       "  'Hitmonlee',\n",
       "  'Horsea',\n",
       "  'Hypno',\n",
       "  'Ivysaur',\n",
       "  'Jigglypuff',\n",
       "  'Jolteon',\n",
       "  'Jynx',\n",
       "  'Kabuto',\n",
       "  'Kabutops',\n",
       "  'Kadabra',\n",
       "  'Kakuna',\n",
       "  'Kangaskhan',\n",
       "  'Kingler',\n",
       "  'Koffing',\n",
       "  'Krabby',\n",
       "  'Lapras',\n",
       "  'Lickitung',\n",
       "  'Machamp',\n",
       "  'Machoke',\n",
       "  'Machop',\n",
       "  'Magikarp',\n",
       "  'Magmar',\n",
       "  'Magnemite',\n",
       "  'Magneton',\n",
       "  'Mankey',\n",
       "  'Marowak',\n",
       "  'Meowth',\n",
       "  'Metapod',\n",
       "  'Mew',\n",
       "  'Mewtwo',\n",
       "  'Moltres',\n",
       "  'MrMime',\n",
       "  'Muk',\n",
       "  'Nidoking',\n",
       "  'Nidoqueen',\n",
       "  'Nidorina',\n",
       "  'Nidorino',\n",
       "  'Ninetales',\n",
       "  'Oddish',\n",
       "  'Omanyte',\n",
       "  'Omastar',\n",
       "  'Onix',\n",
       "  'Paras',\n",
       "  'Parasect',\n",
       "  'Persian',\n",
       "  'Pidgeot',\n",
       "  'Pidgeotto',\n",
       "  'Pidgey',\n",
       "  'Pikachu',\n",
       "  'Pinsir',\n",
       "  'Poliwag',\n",
       "  'Poliwhirl',\n",
       "  'Poliwrath',\n",
       "  'Ponyta',\n",
       "  'Porygon',\n",
       "  'Primeape',\n",
       "  'Psyduck',\n",
       "  'Raichu',\n",
       "  'Rapidash',\n",
       "  'Raticate',\n",
       "  'Rattata',\n",
       "  'Rhydon',\n",
       "  'Rhyhorn',\n",
       "  'Sandshrew',\n",
       "  'Sandslash',\n",
       "  'Scyther',\n",
       "  'Seadra',\n",
       "  'Seaking',\n",
       "  'Seel',\n",
       "  'Shellder',\n",
       "  'Slowbro',\n",
       "  'Slowpoke',\n",
       "  'Snorlax',\n",
       "  'Spearow',\n",
       "  'Squirtle',\n",
       "  'Starmie',\n",
       "  'Staryu',\n",
       "  'Tangela',\n",
       "  'Tauros',\n",
       "  'Tentacool',\n",
       "  'Tentacruel',\n",
       "  'Vaporeon',\n",
       "  'Venomoth',\n",
       "  'Venonat',\n",
       "  'Venusaur',\n",
       "  'Victreebel',\n",
       "  'Vileplume',\n",
       "  'Voltorb',\n",
       "  'Vulpix',\n",
       "  'Wartortle',\n",
       "  'Weedle',\n",
       "  'Weepinbell',\n",
       "  'Weezing',\n",
       "  'Wigglytuff',\n",
       "  'Zapdos',\n",
       "  'Zubat'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataLoaders with help from data_setup.py\n",
    "train_dataloader, test_dataloader, class_names = create_dataloaders(\n",
    "    train_dir=train_dir,\n",
    "    test_dir=test_dir,\n",
    "    transform=auto_transforms,\n",
    "    batch_size=32\n",
    "    )\n",
    "train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f263aaca-0577-4461-a9dc-779854c3ef7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /Users/vanotole/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
      "100%|████████████████████████████████| 20.5M/20.5M [00:01<00:00, 21.1MB/s]\n"
     ]
    }
   ],
   "source": [
    "# OLD: Setup the model with pretrained weights and send it to the target device (this was prior to torchvision v0.13)\n",
    "# model = torchvision.models.efficientnet_b0(pretrained=True).to(device) # OLD method (with pretrained=True)\n",
    "\n",
    "# NEW: Setup the model with pretrained weights and send it to the target device (torchvision v0.13+)\n",
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT # .DEFAULT = best available weights \n",
    "model = torchvision.models.efficientnet_b0(weights=weights).to(device)\n",
    "\n",
    "#model # uncomment to output (it's very long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0cbd1fa-26bf-4324-b04d-ca1f9b5ecb9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
       "============================================================================================================================================\n",
       "EfficientNet (EfficientNet)                                  [32, 3, 224, 224]    [32, 1000]           --                   True\n",
       "├─Sequential (features)                                      [32, 3, 224, 224]    [32, 1280, 7, 7]     --                   True\n",
       "│    └─Conv2dNormActivation (0)                              [32, 3, 224, 224]    [32, 32, 112, 112]   --                   True\n",
       "│    │    └─Conv2d (0)                                       [32, 3, 224, 224]    [32, 32, 112, 112]   864                  True\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 32, 112, 112]   [32, 32, 112, 112]   64                   True\n",
       "│    │    └─SiLU (2)                                         [32, 32, 112, 112]   [32, 32, 112, 112]   --                   --\n",
       "│    └─Sequential (1)                                        [32, 32, 112, 112]   [32, 16, 112, 112]   --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 32, 112, 112]   [32, 16, 112, 112]   1,448                True\n",
       "│    └─Sequential (2)                                        [32, 16, 112, 112]   [32, 24, 56, 56]     --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 16, 112, 112]   [32, 24, 56, 56]     6,004                True\n",
       "│    │    └─MBConv (1)                                       [32, 24, 56, 56]     [32, 24, 56, 56]     10,710               True\n",
       "│    └─Sequential (3)                                        [32, 24, 56, 56]     [32, 40, 28, 28]     --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 24, 56, 56]     [32, 40, 28, 28]     15,350               True\n",
       "│    │    └─MBConv (1)                                       [32, 40, 28, 28]     [32, 40, 28, 28]     31,290               True\n",
       "│    └─Sequential (4)                                        [32, 40, 28, 28]     [32, 80, 14, 14]     --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 40, 28, 28]     [32, 80, 14, 14]     37,130               True\n",
       "│    │    └─MBConv (1)                                       [32, 80, 14, 14]     [32, 80, 14, 14]     102,900              True\n",
       "│    │    └─MBConv (2)                                       [32, 80, 14, 14]     [32, 80, 14, 14]     102,900              True\n",
       "│    └─Sequential (5)                                        [32, 80, 14, 14]     [32, 112, 14, 14]    --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 80, 14, 14]     [32, 112, 14, 14]    126,004              True\n",
       "│    │    └─MBConv (1)                                       [32, 112, 14, 14]    [32, 112, 14, 14]    208,572              True\n",
       "│    │    └─MBConv (2)                                       [32, 112, 14, 14]    [32, 112, 14, 14]    208,572              True\n",
       "│    └─Sequential (6)                                        [32, 112, 14, 14]    [32, 192, 7, 7]      --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 112, 14, 14]    [32, 192, 7, 7]      262,492              True\n",
       "│    │    └─MBConv (1)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      587,952              True\n",
       "│    │    └─MBConv (2)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      587,952              True\n",
       "│    │    └─MBConv (3)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      587,952              True\n",
       "│    └─Sequential (7)                                        [32, 192, 7, 7]      [32, 320, 7, 7]      --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 192, 7, 7]      [32, 320, 7, 7]      717,232              True\n",
       "│    └─Conv2dNormActivation (8)                              [32, 320, 7, 7]      [32, 1280, 7, 7]     --                   True\n",
       "│    │    └─Conv2d (0)                                       [32, 320, 7, 7]      [32, 1280, 7, 7]     409,600              True\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 1280, 7, 7]     [32, 1280, 7, 7]     2,560                True\n",
       "│    │    └─SiLU (2)                                         [32, 1280, 7, 7]     [32, 1280, 7, 7]     --                   --\n",
       "├─AdaptiveAvgPool2d (avgpool)                                [32, 1280, 7, 7]     [32, 1280, 1, 1]     --                   --\n",
       "├─Sequential (classifier)                                    [32, 1280]           [32, 1000]           --                   True\n",
       "│    └─Dropout (0)                                           [32, 1280]           [32, 1280]           --                   --\n",
       "│    └─Linear (1)                                            [32, 1280]           [32, 1000]           1,281,000            True\n",
       "============================================================================================================================================\n",
       "Total params: 5,288,548\n",
       "Trainable params: 5,288,548\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 12.35\n",
       "============================================================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 3452.35\n",
       "Params size (MB): 21.15\n",
       "Estimated Total Size (MB): 3492.77\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print a summary using torchinfo (uncomment for actual output)\n",
    "summary(model=model, \n",
    "        input_size=(32, 3, 224, 224), # make sure this is \"input_size\", not \"input_shape\"\n",
    "        # col_names=[\"input_size\"], # uncomment for smaller output\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f196185e-3a7a-4387-9b2c-3cce54a2b8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all base layers in the \"features\" section of the model (the feature extractor) by setting requires_grad=False\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9404747-0600-4f87-84b5-f64d6015bbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the manual seeds\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# Get the length of class_names (one output unit for each class)\n",
    "output_shape = len(class_names)\n",
    "\n",
    "# Recreate the classifier layer and seed it to the target device\n",
    "model.classifier = torch.nn.Sequential(\n",
    "    torch.nn.Dropout(p=0.2, inplace=True), \n",
    "    torch.nn.Linear(in_features=1280, \n",
    "                    out_features=output_shape, # same number of output units as our number of classes\n",
    "                    bias=True)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a066e21-e870-4d47-af38-723aedd2f251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
       "============================================================================================================================================\n",
       "EfficientNet (EfficientNet)                                  [32, 3, 224, 224]    [32, 150]            --                   Partial\n",
       "├─Sequential (features)                                      [32, 3, 224, 224]    [32, 1280, 7, 7]     --                   False\n",
       "│    └─Conv2dNormActivation (0)                              [32, 3, 224, 224]    [32, 32, 112, 112]   --                   False\n",
       "│    │    └─Conv2d (0)                                       [32, 3, 224, 224]    [32, 32, 112, 112]   (864)                False\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 32, 112, 112]   [32, 32, 112, 112]   (64)                 False\n",
       "│    │    └─SiLU (2)                                         [32, 32, 112, 112]   [32, 32, 112, 112]   --                   --\n",
       "│    └─Sequential (1)                                        [32, 32, 112, 112]   [32, 16, 112, 112]   --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 32, 112, 112]   [32, 16, 112, 112]   (1,448)              False\n",
       "│    └─Sequential (2)                                        [32, 16, 112, 112]   [32, 24, 56, 56]     --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 16, 112, 112]   [32, 24, 56, 56]     (6,004)              False\n",
       "│    │    └─MBConv (1)                                       [32, 24, 56, 56]     [32, 24, 56, 56]     (10,710)             False\n",
       "│    └─Sequential (3)                                        [32, 24, 56, 56]     [32, 40, 28, 28]     --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 24, 56, 56]     [32, 40, 28, 28]     (15,350)             False\n",
       "│    │    └─MBConv (1)                                       [32, 40, 28, 28]     [32, 40, 28, 28]     (31,290)             False\n",
       "│    └─Sequential (4)                                        [32, 40, 28, 28]     [32, 80, 14, 14]     --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 40, 28, 28]     [32, 80, 14, 14]     (37,130)             False\n",
       "│    │    └─MBConv (1)                                       [32, 80, 14, 14]     [32, 80, 14, 14]     (102,900)            False\n",
       "│    │    └─MBConv (2)                                       [32, 80, 14, 14]     [32, 80, 14, 14]     (102,900)            False\n",
       "│    └─Sequential (5)                                        [32, 80, 14, 14]     [32, 112, 14, 14]    --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 80, 14, 14]     [32, 112, 14, 14]    (126,004)            False\n",
       "│    │    └─MBConv (1)                                       [32, 112, 14, 14]    [32, 112, 14, 14]    (208,572)            False\n",
       "│    │    └─MBConv (2)                                       [32, 112, 14, 14]    [32, 112, 14, 14]    (208,572)            False\n",
       "│    └─Sequential (6)                                        [32, 112, 14, 14]    [32, 192, 7, 7]      --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 112, 14, 14]    [32, 192, 7, 7]      (262,492)            False\n",
       "│    │    └─MBConv (1)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      (587,952)            False\n",
       "│    │    └─MBConv (2)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      (587,952)            False\n",
       "│    │    └─MBConv (3)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      (587,952)            False\n",
       "│    └─Sequential (7)                                        [32, 192, 7, 7]      [32, 320, 7, 7]      --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 192, 7, 7]      [32, 320, 7, 7]      (717,232)            False\n",
       "│    └─Conv2dNormActivation (8)                              [32, 320, 7, 7]      [32, 1280, 7, 7]     --                   False\n",
       "│    │    └─Conv2d (0)                                       [32, 320, 7, 7]      [32, 1280, 7, 7]     (409,600)            False\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 1280, 7, 7]     [32, 1280, 7, 7]     (2,560)              False\n",
       "│    │    └─SiLU (2)                                         [32, 1280, 7, 7]     [32, 1280, 7, 7]     --                   --\n",
       "├─AdaptiveAvgPool2d (avgpool)                                [32, 1280, 7, 7]     [32, 1280, 1, 1]     --                   --\n",
       "├─Sequential (classifier)                                    [32, 1280]           [32, 150]            --                   True\n",
       "│    └─Dropout (0)                                           [32, 1280]           [32, 1280]           --                   --\n",
       "│    └─Linear (1)                                            [32, 1280]           [32, 150]            192,150              True\n",
       "============================================================================================================================================\n",
       "Total params: 4,199,698\n",
       "Trainable params: 192,150\n",
       "Non-trainable params: 4,007,548\n",
       "Total mult-adds (G): 12.31\n",
       "============================================================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 3452.13\n",
       "Params size (MB): 16.80\n",
       "Estimated Total Size (MB): 3488.20\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Do a summary *after* freezing the features and changing the output classifier layer (uncomment for actual output)\n",
    "summary(model, \n",
    "        input_size=(32, 3, 224, 224), # make sure this is \"input_size\", not \"input_shape\" (batch_size, color_channels, height, width)\n",
    "        verbose=0,\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dfc718d7-8938-4219-8fe3-e44721abe53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c824dbd1-ced9-4191-b5ce-d75fe7b9cab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Contains functions for training and testing a PyTorch model.\n",
    "\"\"\"\n",
    "import torch\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "def train_step(model: torch.nn.Module, \n",
    "               dataloader: torch.utils.data.DataLoader, \n",
    "               loss_fn: torch.nn.Module, \n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               device: torch.device) -> Tuple[float, float]:\n",
    "  \"\"\"Trains a PyTorch model for a single epoch.\n",
    "\n",
    "  Turns a target PyTorch model to training mode and then\n",
    "  runs through all of the required training steps (forward\n",
    "  pass, loss calculation, optimizer step).\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model to be trained.\n",
    "    dataloader: A DataLoader instance for the model to be trained on.\n",
    "    loss_fn: A PyTorch loss function to minimize.\n",
    "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "  Returns:\n",
    "    A tuple of training loss and training accuracy metrics.\n",
    "    In the form (train_loss, train_accuracy). For example:\n",
    "    \n",
    "    (0.1112, 0.8743)\n",
    "  \"\"\"\n",
    "  # Put model in train mode\n",
    "  model.train()\n",
    "  \n",
    "  # Setup train loss and train accuracy values\n",
    "  train_loss, train_acc = 0, 0\n",
    "  \n",
    "  # Loop through data loader data batches\n",
    "  for batch, (X, y) in enumerate(dataloader):\n",
    "      # Send data to target device\n",
    "      X, y = X.to(device), y.to(device)\n",
    "\n",
    "      # 1. Forward pass\n",
    "      y_pred = model(X)\n",
    "\n",
    "      # 2. Calculate  and accumulate loss\n",
    "      loss = loss_fn(y_pred, y)\n",
    "      train_loss += loss.item() \n",
    "\n",
    "      # 3. Optimizer zero grad\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # 4. Loss backward\n",
    "      loss.backward()\n",
    "\n",
    "      # 5. Optimizer step\n",
    "      optimizer.step()\n",
    "\n",
    "      # Calculate and accumulate accuracy metric across all batches\n",
    "      y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "      train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
    "\n",
    "  # Adjust metrics to get average loss and accuracy per batch \n",
    "  train_loss = train_loss / len(dataloader)\n",
    "  train_acc = train_acc / len(dataloader)\n",
    "  return train_loss, train_acc\n",
    "\n",
    "def test_step(model: torch.nn.Module, \n",
    "              dataloader: torch.utils.data.DataLoader, \n",
    "              loss_fn: torch.nn.Module,\n",
    "              device: torch.device) -> Tuple[float, float]:\n",
    "  \"\"\"Tests a PyTorch model for a single epoch.\n",
    "\n",
    "  Turns a target PyTorch model to \"eval\" mode and then performs\n",
    "  a forward pass on a testing dataset.\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model to be tested.\n",
    "    dataloader: A DataLoader instance for the model to be tested on.\n",
    "    loss_fn: A PyTorch loss function to calculate loss on the test data.\n",
    "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "  Returns:\n",
    "    A tuple of testing loss and testing accuracy metrics.\n",
    "    In the form (test_loss, test_accuracy). For example:\n",
    "    \n",
    "    (0.0223, 0.8985)\n",
    "  \"\"\"\n",
    "  # Put model in eval mode\n",
    "  model.eval() \n",
    "  \n",
    "  # Setup test loss and test accuracy values\n",
    "  test_loss, test_acc = 0, 0\n",
    "  \n",
    "  # Turn on inference context manager\n",
    "  with torch.inference_mode():\n",
    "      # Loop through DataLoader batches\n",
    "      for batch, (X, y) in enumerate(dataloader):\n",
    "          # Send data to target device\n",
    "          X, y = X.to(device), y.to(device)\n",
    "  \n",
    "          # 1. Forward pass\n",
    "          test_pred_logits = model(X)\n",
    "\n",
    "          # 2. Calculate and accumulate loss\n",
    "          loss = loss_fn(test_pred_logits, y)\n",
    "          test_loss += loss.item()\n",
    "          \n",
    "          # Calculate and accumulate accuracy\n",
    "          test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "          test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "          \n",
    "  # Adjust metrics to get average loss and accuracy per batch \n",
    "  test_loss = test_loss / len(dataloader)\n",
    "  test_acc = test_acc / len(dataloader)\n",
    "  return test_loss, test_acc\n",
    "\n",
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          test_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          epochs: int,\n",
    "          device: torch.device) -> Dict[str, List]:\n",
    "  \"\"\"Trains and tests a PyTorch model.\n",
    "\n",
    "  Passes a target PyTorch models through train_step() and test_step()\n",
    "  functions for a number of epochs, training and testing the model\n",
    "  in the same epoch loop.\n",
    "\n",
    "  Calculates, prints and stores evaluation metrics throughout.\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model to be trained and tested.\n",
    "    train_dataloader: A DataLoader instance for the model to be trained on.\n",
    "    test_dataloader: A DataLoader instance for the model to be tested on.\n",
    "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
    "    epochs: An integer indicating how many epochs to train for.\n",
    "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "  Returns:\n",
    "    A dictionary of training and testing loss as well as training and\n",
    "    testing accuracy metrics. Each metric has a value in a list for \n",
    "    each epoch.\n",
    "    In the form: {train_loss: [...],\n",
    "                  train_acc: [...],\n",
    "                  test_loss: [...],\n",
    "                  test_acc: [...]} \n",
    "    For example if training for epochs=2: \n",
    "                 {train_loss: [2.0616, 1.0537],\n",
    "                  train_acc: [0.3945, 0.3945],\n",
    "                  test_loss: [1.2641, 1.5706],\n",
    "                  test_acc: [0.3400, 0.2973]} \n",
    "  \"\"\"\n",
    "  # Create empty results dictionary\n",
    "  results = {\"train_loss\": [],\n",
    "      \"train_acc\": [],\n",
    "      \"test_loss\": [],\n",
    "      \"test_acc\": []\n",
    "  }\n",
    "  \n",
    "  # Loop through training and testing steps for a number of epochs\n",
    "  for epoch in tqdm(range(epochs)):\n",
    "      train_loss, train_acc = train_step(model=model,\n",
    "                                          dataloader=train_dataloader,\n",
    "                                          loss_fn=loss_fn,\n",
    "                                          optimizer=optimizer,\n",
    "                                          device=device)\n",
    "      test_loss, test_acc = test_step(model=model,\n",
    "          dataloader=test_dataloader,\n",
    "          loss_fn=loss_fn,\n",
    "          device=device)\n",
    "      \n",
    "      # Synchronize MPS operations\n",
    "      if str(device) == \"mps\":\n",
    "          torch.mps.synchronize()\n",
    "      \n",
    "      # Print out what's happening\n",
    "      print(\n",
    "          f\"Epoch: {epoch+1} | \"\n",
    "          f\"train_loss: {train_loss:.4f} | \"\n",
    "          f\"train_acc: {train_acc:.4f} | \"\n",
    "          f\"test_loss: {test_loss:.4f} | \"\n",
    "          f\"test_acc: {test_acc:.4f}\"\n",
    "      )\n",
    "\n",
    "      # Update results dictionary\n",
    "      results[\"train_loss\"].append(train_loss)\n",
    "      results[\"train_acc\"].append(train_acc)\n",
    "      results[\"test_loss\"].append(test_loss)\n",
    "      results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "  # Return the filled results at the end of the epochs\n",
    "  return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f7b5cf2-b203-4565-9f28-f4caff331a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "318531e92827450786d3e086aa6c3fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (MPSFloatType) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m start_time \u001b[38;5;241m=\u001b[39m timer()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Setup training and save the results\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                       \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# End the timer and print out how long it took\u001b[39;00m\n\u001b[1;32m     19\u001b[0m end_time \u001b[38;5;241m=\u001b[39m timer()\n",
      "Cell \u001b[0;32mIn[31], line 166\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, test_dataloader, optimizer, loss_fn, epochs, device)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# Loop through training and testing steps for a number of epochs\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs)):\n\u001b[0;32m--> 166\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m     test_loss, test_acc \u001b[38;5;241m=\u001b[39m test_step(model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    172\u001b[0m         dataloader\u001b[38;5;241m=\u001b[39mtest_dataloader,\n\u001b[1;32m    173\u001b[0m         loss_fn\u001b[38;5;241m=\u001b[39mloss_fn,\n\u001b[1;32m    174\u001b[0m         device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;66;03m# Synchronize MPS operations\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[31], line 45\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(model, dataloader, loss_fn, optimizer, device)\u001b[0m\n\u001b[1;32m     42\u001b[0m X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# 1. Forward pass\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# 2. Calculate  and accumulate loss\u001b[39;00m\n\u001b[1;32m     48\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred, y)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/ds_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1678\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mregister_forward_hook\u001b[39m(\n\u001b[1;32m   1679\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1680\u001b[0m     hook: Union[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1687\u001b[0m     always_call: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1688\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RemovableHandle:\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Register a forward hook on the module.\u001b[39;00m\n\u001b[1;32m   1690\u001b[0m \n\u001b[1;32m   1691\u001b[0m \u001b[38;5;124;03m    The hook will be called every time after :func:`forward` has computed an output.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1729\u001b[0m \u001b[38;5;124;03m            ``handle.remove()``\u001b[39;00m\n\u001b[1;32m   1730\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1731\u001b[0m     handle \u001b[38;5;241m=\u001b[39m RemovableHandle(\n\u001b[1;32m   1732\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks,\n\u001b[1;32m   1733\u001b[0m         extra_dict\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m   1734\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks_with_kwargs,\n\u001b[1;32m   1735\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks_always_called,\n\u001b[0;32m-> 1736\u001b[0m         ],\n\u001b[1;32m   1737\u001b[0m     )\n\u001b[1;32m   1738\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks[handle\u001b[38;5;241m.\u001b[39mid] \u001b[38;5;241m=\u001b[39m hook\n\u001b[1;32m   1739\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m with_kwargs:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/ds_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1744\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mmove_to_end(handle\u001b[38;5;241m.\u001b[39mid, last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle\n\u001b[0;32m-> 1747\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_slow_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1748\u001b[0m     tracing_state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_tracing_state()\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_state \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward, torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mScriptMethod):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/ds_env/lib/python3.10/site-packages/torchvision/models/efficientnet.py:343\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    339\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(x)\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m--> 343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_impl(x)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/ds_env/lib/python3.10/site-packages/torchvision/models/efficientnet.py:333\u001b[0m, in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    330\u001b[0m             nn\u001b[38;5;241m.\u001b[39minit\u001b[38;5;241m.\u001b[39muniform_(m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;241m-\u001b[39minit_range, init_range)\n\u001b[1;32m    331\u001b[0m             nn\u001b[38;5;241m.\u001b[39minit\u001b[38;5;241m.\u001b[39mzeros_(m\u001b[38;5;241m.\u001b[39mbias)\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    334\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures(x)\n\u001b[1;32m    336\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/ds_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1678\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mregister_forward_hook\u001b[39m(\n\u001b[1;32m   1679\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1680\u001b[0m     hook: Union[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1687\u001b[0m     always_call: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1688\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RemovableHandle:\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Register a forward hook on the module.\u001b[39;00m\n\u001b[1;32m   1690\u001b[0m \n\u001b[1;32m   1691\u001b[0m \u001b[38;5;124;03m    The hook will be called every time after :func:`forward` has computed an output.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1729\u001b[0m \u001b[38;5;124;03m            ``handle.remove()``\u001b[39;00m\n\u001b[1;32m   1730\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1731\u001b[0m     handle \u001b[38;5;241m=\u001b[39m RemovableHandle(\n\u001b[1;32m   1732\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks,\n\u001b[1;32m   1733\u001b[0m         extra_dict\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m   1734\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks_with_kwargs,\n\u001b[1;32m   1735\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks_always_called,\n\u001b[0;32m-> 1736\u001b[0m         ],\n\u001b[1;32m   1737\u001b[0m     )\n\u001b[1;32m   1738\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks[handle\u001b[38;5;241m.\u001b[39mid] \u001b[38;5;241m=\u001b[39m hook\n\u001b[1;32m   1739\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m with_kwargs:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/ds_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1744\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mmove_to_end(handle\u001b[38;5;241m.\u001b[39mid, last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle\n\u001b[0;32m-> 1747\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_slow_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1748\u001b[0m     tracing_state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_tracing_state()\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_state \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward, torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mScriptMethod):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/ds_env/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;124;03mRuns the forward pass.\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/ds_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1678\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mregister_forward_hook\u001b[39m(\n\u001b[1;32m   1679\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1680\u001b[0m     hook: Union[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1687\u001b[0m     always_call: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1688\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RemovableHandle:\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Register a forward hook on the module.\u001b[39;00m\n\u001b[1;32m   1690\u001b[0m \n\u001b[1;32m   1691\u001b[0m \u001b[38;5;124;03m    The hook will be called every time after :func:`forward` has computed an output.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1729\u001b[0m \u001b[38;5;124;03m            ``handle.remove()``\u001b[39;00m\n\u001b[1;32m   1730\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1731\u001b[0m     handle \u001b[38;5;241m=\u001b[39m RemovableHandle(\n\u001b[1;32m   1732\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks,\n\u001b[1;32m   1733\u001b[0m         extra_dict\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m   1734\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks_with_kwargs,\n\u001b[1;32m   1735\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks_always_called,\n\u001b[0;32m-> 1736\u001b[0m         ],\n\u001b[1;32m   1737\u001b[0m     )\n\u001b[1;32m   1738\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks[handle\u001b[38;5;241m.\u001b[39mid] \u001b[38;5;241m=\u001b[39m hook\n\u001b[1;32m   1739\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m with_kwargs:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/ds_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1744\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mmove_to_end(handle\u001b[38;5;241m.\u001b[39mid, last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle\n\u001b[0;32m-> 1747\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_slow_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1748\u001b[0m     tracing_state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_tracing_state()\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_state \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward, torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mScriptMethod):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/ds_env/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;124;03mRuns the forward pass.\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/ds_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1678\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mregister_forward_hook\u001b[39m(\n\u001b[1;32m   1679\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1680\u001b[0m     hook: Union[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1687\u001b[0m     always_call: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1688\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RemovableHandle:\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Register a forward hook on the module.\u001b[39;00m\n\u001b[1;32m   1690\u001b[0m \n\u001b[1;32m   1691\u001b[0m \u001b[38;5;124;03m    The hook will be called every time after :func:`forward` has computed an output.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1729\u001b[0m \u001b[38;5;124;03m            ``handle.remove()``\u001b[39;00m\n\u001b[1;32m   1730\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1731\u001b[0m     handle \u001b[38;5;241m=\u001b[39m RemovableHandle(\n\u001b[1;32m   1732\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks,\n\u001b[1;32m   1733\u001b[0m         extra_dict\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m   1734\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks_with_kwargs,\n\u001b[1;32m   1735\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks_always_called,\n\u001b[0;32m-> 1736\u001b[0m         ],\n\u001b[1;32m   1737\u001b[0m     )\n\u001b[1;32m   1738\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks[handle\u001b[38;5;241m.\u001b[39mid] \u001b[38;5;241m=\u001b[39m hook\n\u001b[1;32m   1739\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m with_kwargs:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/ds_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1744\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mmove_to_end(handle\u001b[38;5;241m.\u001b[39mid, last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle\n\u001b[0;32m-> 1747\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_slow_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1748\u001b[0m     tracing_state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_tracing_state()\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_state \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward, torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mScriptMethod):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/ds_env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mConv3d\u001b[39;00m(_ConvNd):\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;18m__doc__\u001b[39m \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    553\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies a 3D convolution over an input signal composed of several input\u001b[39;00m\n\u001b[0;32m--> 554\u001b[0m \u001b[38;5;124;03m    planes.\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \n\u001b[1;32m    556\u001b[0m \u001b[38;5;124;03m    In the simplest case, the output value of the layer with input size :math:`(N, C_{in}, D, H, W)`\u001b[39;00m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;124;03m    and output :math:`(N, C_{out}, D_{out}, H_{out}, W_{out})` can be precisely described as:\u001b[39;00m\n\u001b[1;32m    558\u001b[0m \n\u001b[1;32m    559\u001b[0m \u001b[38;5;124;03m    .. math::\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;124;03m        out(N_i, C_{out_j}) = bias(C_{out_j}) +\u001b[39;00m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;124;03m                                \\sum_{k = 0}^{C_{in} - 1} weight(C_{out_j}, k) \\star input(N_i, k)\u001b[39;00m\n\u001b[1;32m    562\u001b[0m \n\u001b[1;32m    563\u001b[0m \u001b[38;5;124;03m    where :math:`\\star` is the valid 3D `cross-correlation`_ operator\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    565\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    566\u001b[0m \n\u001b[1;32m    567\u001b[0m \u001b[38;5;124m    This module supports :ref:`TensorFloat32<tf32_on_ampere>`.\u001b[39m\n\u001b[1;32m    568\u001b[0m \n\u001b[1;32m    569\u001b[0m \u001b[38;5;124m    On certain ROCm devices, when using float16 inputs this module will use :ref:`different precision<fp16_on_mi200>` for backward.\u001b[39m\n\u001b[1;32m    570\u001b[0m \n\u001b[1;32m    571\u001b[0m \u001b[38;5;124m    * :attr:`stride` controls the stride for the cross-correlation.\u001b[39m\n\u001b[1;32m    572\u001b[0m \n\u001b[1;32m    573\u001b[0m \u001b[38;5;124m    * :attr:`padding` controls the amount of padding applied to the input. It\u001b[39m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;124m      can be either a string \u001b[39m\u001b[38;5;124m{{\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m}} or a tuple of ints giving the\u001b[39m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;124m      amount of implicit padding applied on both sides.\u001b[39m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;124;03m    * :attr:`dilation` controls the spacing between the kernel points; also known as the \\u00e0 trous algorithm.\u001b[39;00m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;124;03m      It is harder to describe, but this `link`_ has a nice visualization of what :attr:`dilation` does.\u001b[39;00m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    582\u001b[0m \n\u001b[1;32m    583\u001b[0m \u001b[38;5;124;03m    {groups_note}\u001b[39;00m\n\u001b[1;32m    584\u001b[0m \n\u001b[1;32m    585\u001b[0m \u001b[38;5;124;03m    The parameters :attr:`kernel_size`, :attr:`stride`, :attr:`padding`, :attr:`dilation` can either be:\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \n\u001b[1;32m    587\u001b[0m \u001b[38;5;124;03m        - a single ``int`` -- in which case the same value is used for the depth, height and width dimension\u001b[39;00m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;124;03m        - a ``tuple`` of three ints -- in which case, the first `int` is used for the depth dimension,\u001b[39;00m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;124;03m          the second `int` for the height dimension and the third `int` for the width dimension\u001b[39;00m\n\u001b[1;32m    590\u001b[0m \n\u001b[1;32m    591\u001b[0m \u001b[38;5;124;03m    Note:\u001b[39;00m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;124;03m        {depthwise_separable_note}\u001b[39;00m\n\u001b[1;32m    593\u001b[0m \n\u001b[1;32m    594\u001b[0m \u001b[38;5;124;03m    Note:\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;124;03m        {cudnn_reproducibility_note}\u001b[39;00m\n\u001b[1;32m    596\u001b[0m \n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03m    Note:\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;124;03m        ``padding='valid'`` is the same as no padding. ``padding='same'`` pads\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;124;03m        the input so the output has the shape as the input. However, this mode\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;124;03m        doesn't support any stride values other than 1.\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \n\u001b[1;32m    602\u001b[0m \u001b[38;5;124;03m    Note:\u001b[39;00m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;124;03m        This module supports complex data types i.e. ``complex32, complex64, complex128``.\u001b[39;00m\n\u001b[1;32m    604\u001b[0m \n\u001b[1;32m    605\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;124;03m        in_channels (int): Number of channels in the input image\u001b[39;00m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;124;03m        out_channels (int): Number of channels produced by the convolution\u001b[39;00m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;124;03m        kernel_size (int or tuple): Size of the convolving kernel\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;124;03m        stride (int or tuple, optional): Stride of the convolution. Default: 1\u001b[39;00m\n\u001b[1;32m    610\u001b[0m \u001b[38;5;124;03m        padding (int, tuple or str, optional): Padding added to all six sides of\u001b[39;00m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;124;03m            the input. Default: 0\u001b[39;00m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;124;03m        dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\u001b[39;00m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;124;03m        groups (int, optional): Number of blocked connections from input channels to output channels. Default: 1\u001b[39;00m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;124;03m        bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\u001b[39;00m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;124;03m        padding_mode (str, optional): ``'zeros'``, ``'reflect'``, ``'replicate'`` or ``'circular'``. Default: ``'zeros'``\u001b[39;00m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mreproducibility_notes, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconvolution_notes)\n\u001b[1;32m    617\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    618\u001b[0m \n\u001b[1;32m    619\u001b[0m \u001b[38;5;124m    Shape:\u001b[39m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;124m        - Input: :math:`(N, C_\u001b[39m\u001b[38;5;132;01m{in}\u001b[39;00m\u001b[38;5;124m, D_\u001b[39m\u001b[38;5;132;01m{in}\u001b[39;00m\u001b[38;5;124m, H_\u001b[39m\u001b[38;5;132;01m{in}\u001b[39;00m\u001b[38;5;124m, W_\u001b[39m\u001b[38;5;132;01m{in}\u001b[39;00m\u001b[38;5;124m)` or :math:`(C_\u001b[39m\u001b[38;5;132;01m{in}\u001b[39;00m\u001b[38;5;124m, D_\u001b[39m\u001b[38;5;132;01m{in}\u001b[39;00m\u001b[38;5;124m, H_\u001b[39m\u001b[38;5;132;01m{in}\u001b[39;00m\u001b[38;5;124m, W_\u001b[39m\u001b[38;5;132;01m{in}\u001b[39;00m\u001b[38;5;124m)`\u001b[39m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;124m        - Output: :math:`(N, C_\u001b[39m\u001b[38;5;132;01m{out}\u001b[39;00m\u001b[38;5;124m, D_\u001b[39m\u001b[38;5;132;01m{out}\u001b[39;00m\u001b[38;5;124m, H_\u001b[39m\u001b[38;5;132;01m{out}\u001b[39;00m\u001b[38;5;124m, W_\u001b[39m\u001b[38;5;132;01m{out}\u001b[39;00m\u001b[38;5;124m)` or :math:`(C_\u001b[39m\u001b[38;5;132;01m{out}\u001b[39;00m\u001b[38;5;124m, D_\u001b[39m\u001b[38;5;132;01m{out}\u001b[39;00m\u001b[38;5;124m, H_\u001b[39m\u001b[38;5;132;01m{out}\u001b[39;00m\u001b[38;5;124m, W_\u001b[39m\u001b[38;5;132;01m{out}\u001b[39;00m\u001b[38;5;124m)`,\u001b[39m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;124m          where\u001b[39m\n\u001b[1;32m    623\u001b[0m \n\u001b[1;32m    624\u001b[0m \u001b[38;5;124m          .. math::\u001b[39m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;124m              D_\u001b[39m\u001b[38;5;132;01m{out}\u001b[39;00m\u001b[38;5;124m = \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mlfloor\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mfrac\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mD_\u001b[39m\u001b[38;5;132;01m{in}\u001b[39;00m\u001b[38;5;124m + 2 \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtimes \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;132;01m{padding}\u001b[39;00m\u001b[38;5;124m[0] - \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;132;01m{dilation}\u001b[39;00m\u001b[38;5;124m[0]\u001b[39m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;124m                    \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtimes (\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m_size}[0] - 1) - 1}\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;132;01m{stride}\u001b[39;00m\u001b[38;5;124m[0]} + 1\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mrfloor\u001b[39m\n\u001b[1;32m    627\u001b[0m \n\u001b[1;32m    628\u001b[0m \u001b[38;5;124m          .. math::\u001b[39m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;124m              H_\u001b[39m\u001b[38;5;132;01m{out}\u001b[39;00m\u001b[38;5;124m = \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mlfloor\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mfrac\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mH_\u001b[39m\u001b[38;5;132;01m{in}\u001b[39;00m\u001b[38;5;124m + 2 \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtimes \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;132;01m{padding}\u001b[39;00m\u001b[38;5;124m[1] - \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;132;01m{dilation}\u001b[39;00m\u001b[38;5;124m[1]\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;124m                    \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtimes (\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m_size}[1] - 1) - 1}\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;132;01m{stride}\u001b[39;00m\u001b[38;5;124m[1]} + 1\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mrfloor\u001b[39m\n\u001b[1;32m    631\u001b[0m \n\u001b[1;32m    632\u001b[0m \u001b[38;5;124m          .. math::\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;124m              W_\u001b[39m\u001b[38;5;132;01m{out}\u001b[39;00m\u001b[38;5;124m = \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mlfloor\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mfrac\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mW_\u001b[39m\u001b[38;5;132;01m{in}\u001b[39;00m\u001b[38;5;124m + 2 \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtimes \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;132;01m{padding}\u001b[39;00m\u001b[38;5;124m[2] - \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;132;01m{dilation}\u001b[39;00m\u001b[38;5;124m[2]\u001b[39m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;124m                    \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtimes (\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m_size}[2] - 1) - 1}\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;132;01m{stride}\u001b[39;00m\u001b[38;5;124m[2]} + 1\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mrfloor\u001b[39m\n\u001b[1;32m    635\u001b[0m \n\u001b[1;32m    636\u001b[0m \u001b[38;5;124m    Attributes:\u001b[39m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;124m        weight (Tensor): the learnable weights of the module of shape\u001b[39m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;124m                         :math:`(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m_channels}, \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mfrac\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124min\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m_channels}}\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;132;01m{groups}\u001b[39;00m\u001b[38;5;124m},`\u001b[39m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;124m                         :math:`\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m_size[0]}, \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m_size[1]}, \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m_size[2]})`.\u001b[39m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;124m                         The values of these weights are sampled from\u001b[39m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;124m                         :math:`\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmathcal\u001b[39m\u001b[38;5;132;01m{U}\u001b[39;00m\u001b[38;5;124m(-\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msqrt\u001b[39m\u001b[38;5;132;01m{k}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msqrt\u001b[39m\u001b[38;5;132;01m{k}\u001b[39;00m\u001b[38;5;124m)` where\u001b[39m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;124m                         :math:`k = \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mfrac\u001b[39m\u001b[38;5;132;01m{groups}\u001b[39;00m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mC_\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;132;01m{in}\u001b[39;00m\u001b[38;5;124m * \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mprod_\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mi=0}^\u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m_size}[i]}`\u001b[39m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;124m        bias (Tensor):   the learnable bias of the module of shape (out_channels). If :attr:`bias` is ``True``,\u001b[39m\n\u001b[1;32m    644\u001b[0m \u001b[38;5;124m                         then the values of these weights are\u001b[39m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;124m                         sampled from :math:`\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmathcal\u001b[39m\u001b[38;5;132;01m{U}\u001b[39;00m\u001b[38;5;124m(-\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msqrt\u001b[39m\u001b[38;5;132;01m{k}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msqrt\u001b[39m\u001b[38;5;132;01m{k}\u001b[39;00m\u001b[38;5;124m)` where\u001b[39m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;124m                         :math:`k = \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mfrac\u001b[39m\u001b[38;5;132;01m{groups}\u001b[39;00m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mC_\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;132;01m{in}\u001b[39;00m\u001b[38;5;124m * \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mprod_\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mi=0}^\u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m_size}[i]}`\u001b[39m\n\u001b[1;32m    647\u001b[0m \n\u001b[1;32m    648\u001b[0m \u001b[38;5;124m    Examples::\u001b[39m\n\u001b[1;32m    649\u001b[0m \n\u001b[1;32m    650\u001b[0m \u001b[38;5;124m        >>> # With square kernels and equal stride\u001b[39m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;124m        >>> m = nn.Conv3d(16, 33, 3, stride=2)\u001b[39m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;124m        >>> # non-square kernels and unequal stride and with padding\u001b[39m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;124m        >>> m = nn.Conv3d(16, 33, (3, 5, 2), stride=(2, 1, 1), padding=(4, 2, 0))\u001b[39m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;124m        >>> input = torch.randn(20, 16, 10, 50, 100)\u001b[39m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;124m        >>> output = m(input)\u001b[39m\n\u001b[1;32m    656\u001b[0m \n\u001b[1;32m    657\u001b[0m \u001b[38;5;124m    .. _cross-correlation:\u001b[39m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;124m        https://en.wikipedia.org/wiki/Cross-correlation\u001b[39m\n\u001b[1;32m    659\u001b[0m \n\u001b[1;32m    660\u001b[0m \u001b[38;5;124m    .. _link:\u001b[39m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;124m        https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\u001b[39m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    663\u001b[0m     )\n\u001b[1;32m    665\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    666\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    667\u001b[0m         in_channels: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    677\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    678\u001b[0m     ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m         factory_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m: device, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: dtype}\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/ds_env/lib/python3.10/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (MPSFloatType) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "# Set the random seeds\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# Start the timer\n",
    "from timeit import default_timer as timer \n",
    "start_time = timer()\n",
    "\n",
    "# Setup training and save the results\n",
    "results = train(model=model,\n",
    "                       train_dataloader=train_dataloader,\n",
    "                       test_dataloader=test_dataloader,\n",
    "                       optimizer=optimizer,\n",
    "                       loss_fn=loss_fn,\n",
    "                       epochs=5,\n",
    "                       device=device)\n",
    "\n",
    "# End the timer and print out how long it took\n",
    "end_time = timer()\n",
    "print(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e9cd7f-9a5d-4a81-9c71-28e1b52188c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
